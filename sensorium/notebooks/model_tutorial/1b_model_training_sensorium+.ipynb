{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to train the Baseline Models for the SENSORIUM+ track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This notebook will show how to\n",
    "- instantiate dataloader for the Sensorium+ track\n",
    "- instantiate pytorch model\n",
    "- instantiate a trainer function\n",
    "- train two baselines for this competition track\n",
    "- save the model weights (the model weights can already be found in './model_checkpoints/pretrained/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nnfabrik.builder import get_data, get_model, get_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Instantiate DataLoader for Sensorium+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The only difference to the Sensorium track is that here, we include the behavioral variables and the eye position,\n",
    "by setting include_behavior=True, and include_eye_position=True.\n",
    "this will append the behavioral variables to the input images, and the eye position will be passed to\n",
    "the shifter network of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manya\\sensorium\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks/data/static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\manya\\sensorium\\notebooks\\model_tutorial\\1b_model_training_sensorium+.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dataset_fn \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msensorium.datasets.static_loaders\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dataset_config \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpaths\u001b[39m\u001b[39m'\u001b[39m: filenames,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mnormalize\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39minclude_behavior\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m.25\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                  }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m dataloaders \u001b[39m=\u001b[39m get_data(dataset_fn, dataset_config)\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnfabrik\\builder.py:102\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(dataset_fn, dataset_config)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dataset_fn, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    100\u001b[0m     dataset_fn \u001b[39m=\u001b[39m resolve_data(dataset_fn)\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m dataset_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_config)\n",
      "File \u001b[1;32mc:\\Users\\manya\\sensorium\\sensorium\\datasets\\mouse_loaders.py:362\u001b[0m, in \u001b[0;36mstatic_loaders\u001b[1;34m(paths, batch_size, seed, areas, layers, tier, neuron_ids, neuron_n, exclude_neuron_n, neuron_base_seed, image_ids, image_n, image_base_seed, cuda, normalize, include_behavior, add_behavior_as_channels, exclude, select_input_channel, file_tree, image_condition, inputs_mean, inputs_std, scale, include_eye_position, add_eye_pos_as_channels, include_trial_info_keys, overwrite_data_path, include_px_position, image_reshape_list, trial_idx_selection)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39mif\u001b[39;00m (overwrite_data_path) \u001b[39mand\u001b[39;00m (os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(basepath)):\n\u001b[0;32m    360\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(basepath, path)\n\u001b[1;32m--> 362\u001b[0m out \u001b[39m=\u001b[39m static_loader(\n\u001b[0;32m    363\u001b[0m     path,\n\u001b[0;32m    364\u001b[0m     batch_size,\n\u001b[0;32m    365\u001b[0m     areas\u001b[39m=\u001b[39;49mareas,\n\u001b[0;32m    366\u001b[0m     layers\u001b[39m=\u001b[39;49mlayers,\n\u001b[0;32m    367\u001b[0m     cuda\u001b[39m=\u001b[39;49mcuda,\n\u001b[0;32m    368\u001b[0m     tier\u001b[39m=\u001b[39;49mtier,\n\u001b[0;32m    369\u001b[0m     get_key\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    370\u001b[0m     neuron_ids\u001b[39m=\u001b[39;49mneuron_id,\n\u001b[0;32m    371\u001b[0m     neuron_n\u001b[39m=\u001b[39;49mneuron_n,\n\u001b[0;32m    372\u001b[0m     exclude_neuron_n\u001b[39m=\u001b[39;49mexclude_neuron_n,\n\u001b[0;32m    373\u001b[0m     neuron_base_seed\u001b[39m=\u001b[39;49mneuron_base_seed,\n\u001b[0;32m    374\u001b[0m     image_ids\u001b[39m=\u001b[39;49mimage_id,\n\u001b[0;32m    375\u001b[0m     image_n\u001b[39m=\u001b[39;49mimage_n,\n\u001b[0;32m    376\u001b[0m     image_base_seed\u001b[39m=\u001b[39;49mimage_base_seed,\n\u001b[0;32m    377\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m    378\u001b[0m     include_behavior\u001b[39m=\u001b[39;49minclude_behavior,\n\u001b[0;32m    379\u001b[0m     add_behavior_as_channels\u001b[39m=\u001b[39;49madd_behavior_as_channels,\n\u001b[0;32m    380\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    381\u001b[0m     select_input_channel\u001b[39m=\u001b[39;49mselect_input_channel,\n\u001b[0;32m    382\u001b[0m     file_tree\u001b[39m=\u001b[39;49mfile_tree,\n\u001b[0;32m    383\u001b[0m     image_condition\u001b[39m=\u001b[39;49mimage_condition,\n\u001b[0;32m    384\u001b[0m     inputs_mean\u001b[39m=\u001b[39;49minputs_mean,\n\u001b[0;32m    385\u001b[0m     inputs_std\u001b[39m=\u001b[39;49minputs_std,\n\u001b[0;32m    386\u001b[0m     scale\u001b[39m=\u001b[39;49mscale,\n\u001b[0;32m    387\u001b[0m     include_eye_position\u001b[39m=\u001b[39;49minclude_eye_position,\n\u001b[0;32m    388\u001b[0m     add_eye_pos_as_channels\u001b[39m=\u001b[39;49madd_eye_pos_as_channels,\n\u001b[0;32m    389\u001b[0m     include_trial_info_keys\u001b[39m=\u001b[39;49minclude_trial_info_keys,\n\u001b[0;32m    390\u001b[0m     include_px_position\u001b[39m=\u001b[39;49minclude_px_position,\n\u001b[0;32m    391\u001b[0m     image_reshape_list\u001b[39m=\u001b[39;49mimage_reshape_list,\n\u001b[0;32m    392\u001b[0m     trial_idx_selection\u001b[39m=\u001b[39;49mtrial_idx_selection,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    394\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m dls:\n\u001b[0;32m    395\u001b[0m     dls[k][out[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m out[\u001b[39m1\u001b[39m][k]\n",
      "File \u001b[1;32mc:\\Users\\manya\\sensorium\\sensorium\\datasets\\mouse_loaders.py:122\u001b[0m, in \u001b[0;36mstatic_loader\u001b[1;34m(path, batch_size, areas, layers, tier, neuron_ids, neuron_n, exclude_neuron_n, neuron_base_seed, image_ids, image_n, image_base_seed, get_key, cuda, normalize, exclude, include_behavior, add_behavior_as_channels, select_input_channel, file_tree, image_condition, inputs_mean, inputs_std, scale, include_eye_position, add_eye_pos_as_channels, include_trial_info_keys, include_px_position, image_reshape_list, trial_idx_selection)\u001b[0m\n\u001b[0;32m    119\u001b[0m     data_keys\u001b[39m.\u001b[39mextend(include_trial_info_keys)\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m file_tree:\n\u001b[1;32m--> 122\u001b[0m     dat \u001b[39m=\u001b[39m FileTreeDataset(path, \u001b[39m*\u001b[39;49mdata_keys)\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     dat \u001b[39m=\u001b[39m StaticImageSet(path, \u001b[39m*\u001b[39mdata_keys)\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\neuralpredictors\\data\\datasets\\base.py:317\u001b[0m, in \u001b[0;36mFileTreeDatasetBase.__init__\u001b[1;34m(self, dirname, transforms, use_cache, output_rename, output_dict, *data_keys)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m dirname\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Path(dirname[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m])\u001b[39m.\u001b[39mexists():\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munzip(dirname, Path(dirname)\u001b[39m.\u001b[39;49mabsolute()\u001b[39m.\u001b[39;49mparent)\n\u001b[0;32m    318\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdirname[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m exists already. Not unpacking \u001b[39m\u001b[39m{\u001b[39;00mdirname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\neuralpredictors\\data\\datasets\\statics\\filetree.py:54\u001b[0m, in \u001b[0;36mFileTreeDataset.unzip\u001b[1;34m(self, filename, path)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munzip\u001b[39m(\u001b[39mself\u001b[39m, filename, path):\n\u001b[0;32m     53\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnzipping \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m into \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mwith\u001b[39;00m ZipFile(filename, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m zip_obj:\n\u001b[0;32m     55\u001b[0m         zip_obj\u001b[39m.\u001b[39mextractall(path)\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:1248\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[0;32m   1249\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'notebooks/data/static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip'"
     ]
    }
   ],
   "source": [
    "# loading the SENSORIUM+ dataset\n",
    "filenames = ['notebooks/data/static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip', ]\n",
    "\n",
    "\n",
    "dataset_fn = 'sensorium.datasets.static_loaders'\n",
    "dataset_config = {'paths': filenames,\n",
    "                 'normalize': True,\n",
    "                 'include_behavior': True,\n",
    "                 'include_eye_position': True,\n",
    "                 'batch_size': 1,\n",
    "                 'scale':.25,\n",
    "                 }\n",
    "\n",
    "dataloaders = get_data(dataset_fn, dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instantiate State of the Art Model (SOTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because the behavioral variables are available, we instantiate the Shifter network\n",
    "by setting Shifter=True in the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "  'stack': -1,\n",
    "  'layers': 4,\n",
    "  'input_kern': 9,\n",
    "  'gamma_input': 6.3831,\n",
    "  'gamma_readout': 0.0076,\n",
    "  'hidden_kern': 7,\n",
    "  'hidden_channels': 64,\n",
    "  'depth_separable': True,\n",
    "  'grid_mean_predictor': {'type': 'cortex',\n",
    "   'input_dimensions': 2,\n",
    "   'hidden_layers': 1,\n",
    "   'hidden_features': 30,\n",
    "   'final_tanh': True},\n",
    "  'init_sigma': 0.1,\n",
    "  'init_mu_range': 0.3,\n",
    "  'gauss_type': 'full',\n",
    "  'shifter': True,\n",
    "}\n",
    "\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the behavioral variables are available, we instantiate the Shifter network\n",
    "by setting Shifter=True in the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "  'stack': -1,\n",
    "  'layers': 4,\n",
    "  'input_kern': 9,\n",
    "  'gamma_input': 6.3831,\n",
    "  'gamma_readout': 0.0076,\n",
    "  'hidden_kern': 7,\n",
    "  'hidden_channels': 64,\n",
    "  'depth_separable': True,\n",
    "  'grid_mean_predictor': {'type': 'cortex',\n",
    "   'input_dimensions': 2,\n",
    "   'hidden_layers': 1,\n",
    "   'hidden_features': 30,\n",
    "   'final_tanh': True},\n",
    "  'init_sigma': 0.1,\n",
    "  'init_mu_range': 0.3,\n",
    "  'gauss_type': 'full',\n",
    "  'shifter': True,\n",
    "}\n",
    "\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configure Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer_fn = \"sensorium.training.standard_trainer\"\n",
    "\n",
    "trainer_config = {'max_iter': 1,\n",
    "                 'verbose': False,\n",
    "                 'lr_decay_steps': 4,\n",
    "                 'avg_loss': False,\n",
    "                 'lr_init': 0.009,\n",
    "                 }\n",
    "\n",
    "trainer = get_trainer(trainer_fn=trainer_fn, \n",
    "                     trainer_config=trainer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4471/4471 [02:31<00:00, 29.45it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(model, dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model_checkpoints/sensorium_p_sota_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\manya\\sensorium\\notebooks\\model_tutorial\\1b_model_training_sensorium+.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/manya/sensorium/notebooks/model_tutorial/1b_model_training_sensorium%2B.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(), \u001b[39m'\u001b[39;49m\u001b[39m./model_checkpoints/sensorium_p_sota_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:369\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39m\"\"\"Saves an object to a disk file.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[39mSee also: `saving-loading-tensors`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 369\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    371\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\manya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model_checkpoints/sensorium_p_sota_model.pth'"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './model_checkpoints/sensorium_p_sota_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model_checkpoints/pretrained/sensorium_p_sota_model.pth\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train a simple LN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this will remove all nonlinearities from the CNN, and creates essentially a ln model: linear core + readout, with a subsequent non-linearity\n",
    "\n",
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "              'stack': -1,\n",
    "              'layers': 3,\n",
    "              'input_kern': 9,\n",
    "              'gamma_input': 6.3831,\n",
    "              'gamma_readout': 0.0076,\n",
    "              'hidden_kern': 7,\n",
    "              'hidden_channels': 64,\n",
    "              'grid_mean_predictor': {'type': 'cortex',\n",
    "              'input_dimensions': 2,\n",
    "              'hidden_layers': 1,\n",
    "              'hidden_features': 30,\n",
    "              'final_tanh': True},\n",
    "              'depth_separable': True,\n",
    "              'init_sigma': 0.1,\n",
    "              'init_mu_range': 0.3,\n",
    "              'gauss_type': 'full',\n",
    "              'linear': True,\n",
    "              'shifter': True,\n",
    "               }\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4471/4471 [01:19<00:00, 56.15it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(model, dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manya\\Sensorium\\notebooks\\model_tutorial\n"
     ]
    }
   ],
   "source": [
    "%cd c:\\Users\\manya\\Sensorium\\notebooks\\model_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_checkpoints/sensorium_p_ln_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model_checkpoints/pretrained/sensorium_p_ln_model.pth\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "41072853362711b642466fa83666684f867a13cbda69dc0fd8211c5c77b13bb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
